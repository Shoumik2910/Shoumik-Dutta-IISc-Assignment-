# -*- coding: utf-8 -*-
"""IIScAssignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l-lcBEGdr0wUfkUkBLLRi22AhHWx8sRJ
"""

import pandas as pd
df=pd.read_csv("/content/drive/MyDrive/p1_movie_metadata.csv")
df.head()

df.describe()

null_counts = df.isnull().sum()

# Create a DataFrame with column names and corresponding null counts
null_counts_df = pd.DataFrame({'Column Name': null_counts.index, 'Null Count': null_counts.values})

null_counts_df

df.nunique()

df_cleaned = df.dropna(subset=['director_name','genres','title_year'])
df_cleaned

null_counts = df_cleaned.isnull().sum()

# Create a DataFrame with column names and corresponding null counts
null_counts_df = pd.DataFrame({'Column Name': null_counts.index, 'Null Count': null_counts.values})
null_counts_df



df_cleaned["Total facebook likes"]=df_cleaned["director_facebook_likes"]+df_cleaned["actor_1_facebook_likes"]+df_cleaned["actor_2_facebook_likes"]+df_cleaned["actor_3_facebook_likes"]+df_cleaned["cast_total_facebook_likes"]+df_cleaned["movie_facebook_likes"]

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize relationships between features
# sns.pairplot(df[['num_critic_for_reviews', 'duration', 'gross', 'num_voted_users', 'Total facebook likes','title_year']])
# plt.show()

# Correlation heatmap
corr = df_cleaned[['num_critic_for_reviews', 'duration', 'gross', 'num_voted_users', 'Total facebook likes','title_year','imdb_score','num_user_for_reviews','aspect_ratio','budget','facenumber_in_poster']].corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

new_df = df_cleaned[['director_name', 'genres','title_year']].copy()
new_df.head()

null_counts = new_df.isnull().sum()

# Create a DataFrame with column names and corresponding null counts
null_counts_df = pd.DataFrame({'Column Name': null_counts.index, 'Null Count': null_counts.values})
null_counts_df

new_df.info()

new_df['genres'] = new_df['genres'].astype(str)
new_df

new_df.info()

# Example string
new_df['genres'] = new_df['genres'].apply(lambda x: x.split('|'))

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
new_df['director_name'] = le.fit_transform(new_df['director_name'])
new_df

flattened_df = pd.DataFrame(new_df['genres'].explode())

# Step 2: Count occurrences of each element
element_counts = flattened_df['genres'].value_counts()

element_counts

new_df["director_name"].nunique()

from sklearn.preprocessing import MultiLabelBinarizer

multilabel_binarizer = MultiLabelBinarizer()
multilabel_binarizer.fit(new_df['genres'])

# transform target variable
y1= multilabel_binarizer.transform(new_df['genres'])
y1

multilabel_binarizer.inverse_transform(y1)[0]

from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import numpy as np
X=new_df[["director_name"]]

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2,random_state=42,shuffle=False)
svm = SVC()
mnb = MultinomialNB()
ovr_mnb= OneVsRestClassifier(mnb)
log_reg = LogisticRegression()
knn = KNeighborsClassifier()
svm_ovr = OneVsRestClassifier(svm)
log_reg_ovr = OneVsRestClassifier(log_reg)
knn_ovr = OneVsRestClassifier(knn)
# Train each classifier separately
svm_ovr.fit(X_train, y_train)
log_reg_ovr.fit(X_train, y_train)
knn_ovr.fit(X_train, y_train)
ovr_mnb.fit(X_train,y_train)
# Make predictions for each classifier
svm_pred = svm_ovr.predict(X_test)
log_reg_pred = log_reg_ovr.predict(X_test)
knn_pred = knn_ovr.predict(X_test)
mnb_pred=ovr_mnb.predict(X_test)


print("Training set length",len(X_train))
print("Testing set length",len(X_test))

# Evaluate accuracy
svm_f1 = f1_score(y_test, svm_pred,average="micro")
# svm_recall = recall_score(y_test, svm_pred,average="micro")
# svm_precision = f1_score(y_test, svm_pred,average="micro")
log_f1 = f1_score(y_test, log_reg_pred,average="micro")
knn_f1 = f1_score(y_test, knn_pred,average="micro")
mnb_f1 = f1_score(y_test, mnb_pred,average="micro")
log_acc = [accuracy_score(y_test[i], log_reg_pred[i]) for i in range(len(y_test))]
average_accuracy_log = sum(log_acc) / len(log_acc)
svm_acc = [accuracy_score(y_test[i], svm_pred[i]) for i in range(len(y_test))]
average_accuracy_svm = sum(svm_acc) / len(svm_acc)
knn_acc = [accuracy_score(y_test[i], knn_pred[i]) for i in range(len(y_test))]
average_accuracy_knn = sum(knn_acc) / len(knn_acc)
mnb_acc = [accuracy_score(y_test[i], mnb_pred[i]) for i in range(len(y_test))]
average_accuracy_mnb = sum(mnb_acc) / len(mnb_acc)

# print("Label Accuracies:", label_accuracies)
# print("Average Accuracy:", average_accuracy)
print("F1 score for svm is:", svm_f1)
print("F1 score for logistic regression is:", log_f1)
print("F1 score for knn is:", knn_f1)
print("F1 score for Naive Bayes is:", mnb_f1)
print("Accuracy for logistic regression is:", average_accuracy_log)
print("Accuracy for svm is:", average_accuracy_svm)
print("Accuracy for knn is:", average_accuracy_knn)
print("Accuracy for Naive Bayes is:", average_accuracy_mnb)

y_test[0]

multilabel_binarizer.inverse_transform(y_test)[0]

print("SVM Predictions:", multilabel_binarizer.inverse_transform(svm_pred)[0] ,"for director",le.inverse_transform(X_test)[0])
print("Logistic Regression Predictions:", multilabel_binarizer.inverse_transform(log_reg_pred)[0],"for director",le.inverse_transform(X_test)[0])
print("KNN Predictions:", multilabel_binarizer.inverse_transform(knn_pred)[0],"for director",le.inverse_transform(X_test)[0])
print("Naive Bayes Predictions:", multilabel_binarizer.inverse_transform(mnb_pred)[0],"for director",le.inverse_transform(X_test)[0])

common_elements3 = [len(set( multilabel_binarizer.inverse_transform(mnb_pred)[i]) & set( multilabel_binarizer.inverse_transform(y_test)[i])) for i in range(len(y_test))]
sum(common_elements3)

common_elements = [len(set( multilabel_binarizer.inverse_transform(svm_pred)[i]) & set( multilabel_binarizer.inverse_transform(y_test)[i])) for i in range(len(y_test))]

sum(common_elements)

common_elements1 = [len(set( multilabel_binarizer.inverse_transform(log_reg_pred)[i]) & set( multilabel_binarizer.inverse_transform(y_test)[i])) for i in range(len(y_test))]

sum(common_elements1)

sum([len(multilabel_binarizer.inverse_transform(y_test)[i]) for i in range(len(y_test))])

common_elements2 = [len(set( multilabel_binarizer.inverse_transform(knn_pred)[i]) & set( multilabel_binarizer.inverse_transform(y_test)[i])) for i in range(len(y_test))]
sum(common_elements2)

!pip install surprise

from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import SVD
from surprise import accuracy

# Load the data
reader = Reader(rating_scale=(new_df['title_year'].min(), new_df['title_year'].max()))
data_surprise = Dataset.load_from_df(df_cleaned[['director_name', 'genres','title_year']].copy(), reader)

# Train-test split
trainset, testset = train_test_split(data_surprise, test_size=0.2, random_state=42)

# Train the model
model = SVD()
model.fit(trainset)

# Make predictions
predictions = model.test(testset)

# Calculate RMSE
rmse = accuracy.rmse(predictions)
print("Root Mean Squared Error:", rmse)

tuple1=('Action', 'Crime', 'Drama', 'Thriller')

le.inverse_transform(X_test)[0]

director_name = le.inverse_transform(X_test)[0]   # Replace with the director's name you want to make predictions for
movie_release_year1 = model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(knn_pred)[0])).est
movie_release_year2 = model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(log_reg_pred)[0])).est
movie_release_year3 = model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(mnb_pred)[0])).est
movie_release_year4 = model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(svm_pred)[0])).est
print("Predicted Release Year is", int(movie_release_year1), "with genres",multilabel_binarizer.inverse_transform(knn_pred)[0])
print("Predicted Release Year is", int(movie_release_year2), "with genres",multilabel_binarizer.inverse_transform(log_reg_pred)[0])
print("Predicted Release Year is", int(movie_release_year3), "with genres",multilabel_binarizer.inverse_transform(mnb_pred)[0])
print("Predicted Release Year is", int(movie_release_year4), "with genres",multilabel_binarizer.inverse_transform(svm_pred)[0])

data = {'Model_for_Genre_prediction': ['SVM','Naive_Bayes','Logistic Regression','K-Nearest-Neighbours(n_neighbours=5)'],
        'Model_for_Year_prediction':['SVD(RMSE=12.1474)']*4,
        'Model_accuracies_in_multilabel_classification': [average_accuracy_svm,average_accuracy_mnb,average_accuracy_log,average_accuracy_knn],
        'F1_score': [svm_f1,mnb_f1,log_f1,knn_f1],
        'Genres_correctly predicted per row for a total of 2276 genres accross test_dataset': [sum(common_elements),sum(common_elements3),sum(common_elements1),sum(common_elements2)],
        'Release_year prediction for director name= Mark L. Lester': [ int(model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(svm_pred)[0])).est), int(model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(mnb_pred)[0])).est), int(model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(log_reg_pred)[0])).est), int(model.predict(uid=director_name, iid='|'.join(multilabel_binarizer.inverse_transform(knn_pred)[0])).est)],
        'Genres_prediction for director name= Mark L. Lester': [multilabel_binarizer.inverse_transform(svm_pred)[0],multilabel_binarizer.inverse_transform(mnb_pred)[0],multilabel_binarizer.inverse_transform(log_reg_pred)[0],multilabel_binarizer.inverse_transform(knn_pred)[0]]
        }
df_res=pd.DataFrame(data)
df_res